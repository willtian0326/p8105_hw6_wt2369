---
title: "Homework 6"
author: "Wenxin Tian"
date: "`r Sys.Date()`"
output: github_document
---

```{r}
library(tidyverse)
library(modelr)
```

## Problem 1:

__Data Import:__

```{r}
homicide =
  read_csv("./data/homicide-data.csv") |>
  mutate(
    city_state = paste(city, state, sep = ", "),
    resolved = as.numeric(disposition == "Closed by arrest")
  ) |>
  filter(
    !city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL"),
    victim_race %in% c("White", "Black")
  ) |>
  mutate(victim_age = as.numeric(victim_age)) |>
  drop_na(victim_age) |>
  select(resolved, victim_age, victim_race, victim_sex, city_state)
  
```

__GLM:__

```{r}
baltimore = homicide |>
  filter(city_state == "Baltimore, MD")

baltimore_glm = 
  baltimore |>
  glm(resolved ~ victim_age + victim_race + victim_sex, data = _, family = binomial())


# Confidence interval??

baltimore_glm |>
  broom::tidy() |> 
  mutate(OR = exp(estimate)) |>
  select(term, log_OR = estimate, OR, p.value) |> 
  knitr::kable(digits = 3)

baltimore |>
  add_predictions(baltimore_glm) |>
  mutate(prob = boot::inv.logit(pred))
```

## Problem 2:

__Data Import:__

```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2022-01-01",
    date_max = "2022-12-31") |>
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) |>
  select(name, id, everything())
```

__Bootstrapping:__

```{r}
bootstraps =
  weather_df |>
  bootstrap(5000) 

# r2:
r2 =
  bootstraps |>
  mutate(
    models = map(strap, \(df) lm(tmax ~ tmin + prcp, data = df) ),
    results = map(models, broom::glance)) |> 
  select(-strap, -models) |> 
  unnest(results)

# log beta:

log_beta =
  bootstraps |>
  mutate(
    models = map(strap, \(df) lm(tmax ~ tmin + prcp, data = df) ),
    results = map(models, broom::tidy)) |> 
  select(-strap, -models) |> 
  unnest(results)
```

__Plot:__

```{r}
# Note: negative log transformation?

# intercept: beta0, tmin: beta1, prcp: beta3
log_beta |>
  pivot_wider(names_from = term, values_from = estimate) |>
  group_by(.id) |>
  mutate(intercept = `(Intercept)`) |>
  fill(intercept, tmin, prcp, .direction = 'up') |>
  fill(intercept, tmin, .direction = 'down') |>
  summarize(log_beta = log(intercept * tmin)) |>
  distinct() |>
  ggplot(aes(x = log_beta)) +
  geom_density() +
  labs(title = "Log Beta")

r2 |>
  ggplot(aes(x = r.squared)) +
  geom_density() +
  labs(title = "r squared")
```

For both the r squared and log(beta0 * beta1) estimates, a normal distribution was seen. The log beta distribution is centered around 2.10, whereas the r2 distribution is centered around 0.91, which indicates a strong correlation between predictor and outcome. One thing to note is that the product of beta 1 and beta 2 are often negative and cannot be log transformed, so I guess the question meant to ask log(beta0 * beta1), which is positive. 

__Quantile:__

```{r}
# Quantile for r2:
quantile(r2$r.squared, probs = c(0.025, 0.975))

# Quantile for log beta:
logbeta_clean = 
  log_beta |>
  pivot_wider(names_from = term, values_from = estimate) |>
  group_by(.id) |>
  mutate(intercept = `(Intercept)`) |>
  fill(intercept, tmin, prcp, .direction = 'up') |>
  fill(intercept, tmin, .direction = 'down') |>
  summarize(log_beta = log(intercept * tmin)) |>
  distinct()

quantile(logbeta_clean$log_beta, probs = c(0.025, 0.975))
```

## Problem 3:

__Data Import:__

```{r}
bwt_df =
  read_csv("./data/birthweight.csv") |>
  mutate(
    mrace = case_match(
      mrace,
      1 ~ "White",
      2 ~ "Black",
      3 ~ "Asian",
      4 ~ "Puerto Rican",
      8 ~ "Other"
    ),
    mrace = as.factor(mrace),
    fincome = as.factor(fincome),
    #bhead = as.factor(bhead)
    #ppwt = as.factor(ppwt)
  )
```

__Regression Proposal:__

I propose a multiple linear regression against baby's head circumfrance at birth for the fact that head makes up a considerable proportion of the body weight. Another reason is that after plotting multiple variables against `bwt`, none of them showed any linearity with bwt except for `bhead`. I believe mother's weight plays an important role in the birthweight of babies, and mother's weight should also be correlated with family income.

```{r}
bwt_df |>
  ggplot(aes(bhead, bwt)) +
  geom_point()

mod1 = lm(bwt ~ bhead, data = bwt_df)
mod1 |> broom::tidy()
mod1 |> broom::glance()

bwt_df |>
  add_predictions(mod1) |>
  add_residuals(mod1) |>
  ggplot(aes(x = pred, y = resid)) +
  geom_point()

bwt_df |>
  add_predictions(mod1) |>
  ggplot(aes(x = bhead, y = bwt)) +
  geom_point() +
  geom_line(aes(y = pred), color = "red") 
```

From the summary, we see a relatively strong correlation between `bhead` and `bwt`, which is also shown in the plots.

__Cross Validation:__

```{r}
mod2 = 
  lm(bwt ~ blength + gaweeks, data = bwt_df)
mod3 =
  lm(bwt ~ blength + bhead + babysex
     + blength * bhead 
     + blength * babysex 
     + bhead * babysex
     + blength * bhead * babysex,
     data = bwt_df)

cv_df = 
  crossv_mc(bwt_df, 100) 

cv_df =
  cv_df |> 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))

cv_df = 
  cv_df |> 
  mutate(
    mod1  = map(train, \(df) lm(bwt ~ bhead, data = df)),
    mod2  = map(train, \(df) lm(bwt ~ blength + gaweeks, data = df)),
    mod3  = map(train, \(df) lm(bwt ~ blength + bhead + babysex
                                + blength * bhead 
                                + blength * babysex 
                                + bhead * babysex
                                + blength * bhead * babysex,
                                data = df))) |> 
  mutate(
    rmse_mod1 = map2_dbl(mod1, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_mod2 = map2_dbl(mod2, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_mod3 = map2_dbl(mod3, test, \(mod, df) rmse(model = mod, data = df)))

cv_df |> 
  select(starts_with("rmse")) |> 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") |> 
  mutate(model = fct_inorder(model)) |> 
  ggplot(aes(x = model, y = rmse)) + geom_violin()
```

From the plot, we wee that the model that I proposed has a high prediction error, whereas the the most complex model proposed on the assignment has the lowest. 
```{r}
#scratchpaper

dbinom(1, 10, 0.75) * dpois(1, 2) + dbinom(2, 10, .75) * dpois(0, 2) + dbinom(0, 10, .75) * dpois(2, 2)
exp(-2) + 1 / 4^10 - exp(-2) / 4^10
```


